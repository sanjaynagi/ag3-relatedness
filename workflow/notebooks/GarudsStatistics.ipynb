{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "119103c0",
   "metadata": {},
   "source": [
    "This notebook calculates G12/G123/H12/H123 across a chromosomal arm. Lets first designate our parameters which will be passed to the notebook using papermill. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5666e49f",
   "metadata": {
    "tags": [
     "parameters"
    ]
   },
   "outputs": [],
   "source": [
    "# Garuds Selection Scans # \n",
    "cloud = snakemake.params['cloud']\n",
    "ag3_sample_sets = snakemake.params['ag3_sample_sets']\n",
    "contig = snakemake.wildcards['contig']\n",
    "stat = snakemake.params['GarudsStat']\n",
    "windowSize = snakemake.params['windowSize']\n",
    "windowStep = snakemake.params['windowStep']\n",
    "cutHeight = snakemake.params['cutHeight'] if stat in ['G12', 'G123'] else []\n",
    "metaColumns = \"species\"\n",
    "minPopSize = 15"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "118d23b1",
   "metadata": {},
   "source": [
    "Load the required libraries. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3bd94d79",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.stderr = open(snakemake.log[0], \"w\")\n",
    "\n",
    "import probetools as probe\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import allel\n",
    "import dask.array as da\n",
    "import scipy\n",
    "import seaborn as sns\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5f2a0608",
   "metadata": {},
   "source": [
    "Then we load the paths to genotype data, if we are not using the malariagen_data API."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7505f650",
   "metadata": {},
   "outputs": [],
   "source": [
    "if not cloud:\n",
    "    genotypePath = snakemake.input['genotypes'] if stat in ['G12', 'G123'] else []\n",
    "    haplotypePath = snakemake.input['haplotypes'] if stat in ['H1', 'H12', 'H2/1'] else []\n",
    "    positionsPath = snakemake.input['positions']\n",
    "    siteFilterPath = snakemake.input['siteFilters']\n",
    "else:\n",
    "    genotypePath = []\n",
    "    haplotypePath = []\n",
    "    positionsPath = []\n",
    "    siteFilterPath = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee8014a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load metadata \n",
    "if cloud:\n",
    "    import malariagen_data\n",
    "    ag3 = malariagen_data.Ag3()\n",
    "    metadata = ag3.sample_metadata(sample_sets=ag3_sample_sets)\n",
    "else:\n",
    "    metadata = pd.read_csv(snakemake.params['metadata'], sep=\"\\t\")\n",
    "\n",
    "# Load arrays \n",
    "if stat in ['H1', 'H12', 'H2/1']:\n",
    "    haps, pos = probe.loadZarrArrays(haplotypePath, positionsPath, siteFilterPath=None, haplotypes=True, cloud=cloud, contig=contig)\n",
    "elif stat in ['G12', 'G123']:\n",
    "    snps, pos = probe.loadZarrArrays(genotypePath, positionsPath, siteFilterPath=siteFilterPath, haplotypes=False, cloud=cloud, contig=contig)\n",
    "else:\n",
    "    raise AssertionError(\"The statistic selected is not 'G12, G123, or H12\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6921870",
   "metadata": {},
   "source": [
    "Now lets define some function that will do the Garuds calculations for us. For the H statistics we use scikit-allel, the G statistics require us to make our own function which clusters multi-locus genotypes.  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "08ea8f04",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define functions\n",
    "def clusterMultiLocusGenotypes(gnalt, cut_height=0.1, metric='euclidean', g=2):\n",
    "    \"\"\"\n",
    "    Hierarchically clusters genotypes and calculates G12 statistic. \n",
    "    \"\"\"\n",
    "    # cluster the genotypes in the window\n",
    "    dist = scipy.spatial.distance.pdist(gnalt.T, metric=metric)\n",
    "    if metric in {'hamming', 'jaccard'}:\n",
    "        # convert distance to number of SNPs, easier to interpret\n",
    "        dist *= gnalt.shape[0]\n",
    "\n",
    "    Z = scipy.cluster.hierarchy.linkage(dist, method='single')\n",
    "    cut = scipy.cluster.hierarchy.cut_tree(Z, height=cut_height)[:, 0]\n",
    "    cluster_sizes = np.bincount(cut)\n",
    "    #clusters = [np.nonzero(cut == i)[0] for i in range(cut.max() + 1)] #returns indices of individuals in each cluster\n",
    "    \n",
    "    # get freq of clusters and sort by largest freq\n",
    "    freqs = cluster_sizes/gnalt.shape[1]\n",
    "    freqs = np.sort(freqs)[::-1]\n",
    "    \n",
    "    # calculate garuds statistic\n",
    "    gStat = np.sum(freqs[:g])**2 + np.sum(freqs[g:]**2)\n",
    "    \n",
    "    return(gStat)\n",
    "\n",
    "\n",
    "def garudsStat(stat, geno, pos, cut_height=None, metric='euclidean', window_size=1200, step_size=600):\n",
    "    \n",
    "    \"\"\"\n",
    "    Calculates G12/G123/H12\n",
    "    \"\"\"\n",
    "        \n",
    "    # Do we want to cluster the Multi-locus genotypes (MLGs), or just group MLGs if they are identical\n",
    "    if stat == \"G12\":\n",
    "        garudsStat = allel.moving_statistic(geno, clusterMultiLocusGenotypes, size=window_size, step=step_size, metric=metric, cut_height=cut_height, g=2)\n",
    "    elif stat == \"G123\":\n",
    "        garudsStat = allel.moving_statistic(geno, clusterMultiLocusGenotypes, size=window_size, step=step_size, metric=metric, cut_height=cut_height, g=3)\n",
    "    elif stat == \"H12\":\n",
    "        garudsStat,_,_,_ = allel.moving_garud_h(geno, size=window_size, step=step_size)\n",
    "    else:\n",
    "        raise ValueError(\"Statistic is not G12/G123/H12\")\n",
    "\n",
    "    midpoint = allel.moving_statistic(pos, np.median, size=window_size, step=step_size)\n",
    "    \n",
    "    return(garudsStat, midpoint)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ce676450",
   "metadata": {},
   "outputs": [],
   "source": [
    "#### Load cohort data and their indices in genotype data\n",
    "### run garudStat for that query. already loaded contigs \n",
    "cohorts = probe.getCohorts(metadata=metadata, \n",
    "                    columns=metaColumns, \n",
    "                    minPopSize=minPopSize, exclude=True)\n",
    "print(cohorts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "da86857c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loop through each cohort, manipulate genotype arrays and calculate chosen Garuds Statistic\n",
    "for idx, cohort in cohorts.iterrows():\n",
    "\n",
    "    if stat in ['H1', 'H12', 'H123']:\n",
    "        # get indices for haplotype Array and filter\n",
    "        hapInds = np.sort(np.concatenate([np.array(cohort['indices'])*2, np.array(cohort['indices']*2)+1]))\n",
    "        gt_cohort = haps.take(hapInds, axis=1)\n",
    "    elif stat in ['G12', 'G123']:\n",
    "        # filter to correct loc, year, species individuals\n",
    "        gt_cohort = snps.take(cohort['indices'], axis=1)\n",
    "    else:\n",
    "        raise ValueError(\"Statistic is not G12/G123/H1/H12\")\n",
    "\n",
    "    probe.log(f\"--------- Running {stat} on {cohort['cohortText']} | Chromosome {contig} ----------\")\n",
    "    probe.log(\"filter to biallelic segregating sites\")\n",
    "\n",
    "    ac_cohort = gt_cohort.count_alleles(max_allele=3).compute()\n",
    "    # N.B., if going to use to_n_alt later, need to make sure sites are \n",
    "    # biallelic and one of the alleles is the reference allele\n",
    "    ref_ac = ac_cohort[:, 0]\n",
    "    loc_sites = ac_cohort.is_biallelic() & (ref_ac > 0)\n",
    "    gt_seg = da.compress(loc_sites, gt_cohort, axis=0)\n",
    "    pos_seg = da.compress(loc_sites, pos, axis=0)\n",
    "\n",
    "    probe.log(f\"compute input data for {stat}\")\n",
    "    pos_seg = pos_seg.compute()\n",
    "\n",
    "    if stat in ['G12', 'G123']:\n",
    "        gt_seg = allel.GenotypeDaskArray(gt_seg).to_n_alt().compute()\n",
    "\n",
    "    # calculate G12/G123/H12 and plot figs \n",
    "    gStat, midpoint = garudsStat(stat=stat,\n",
    "                                geno=gt_seg, \n",
    "                                pos=pos_seg, \n",
    "                                cut_height=cutHeight,\n",
    "                                metric='euclidean',\n",
    "                                window_size=windowSize,\n",
    "                                step_size=windowStep)\n",
    "\n",
    "    probe.windowedPlot(statName=stat, \n",
    "                cohortText = cohort['cohortText'],\n",
    "                cohortNoSpaceText= cohort['cohortNoSpaceText'],\n",
    "                values=gStat, \n",
    "                midpoints=midpoint,\n",
    "                prefix=f\"results/selection/{stat}\", \n",
    "                contig=contig,\n",
    "                colour=cohort['colour'],\n",
    "                ymin=0,\n",
    "                ymax=0.5)"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Tags",
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
