{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import allel\n",
    "import pandas as pd \n",
    "from datetime import date\n",
    "import numpy as np\n",
    "import dask\n",
    "import dask.dataframe as dd\n",
    "import dask.array as da\n",
    "from pathlib import Path\n",
    "dask.config.set(**{'array.slicing.split_large_chunks': True})\n",
    "\n",
    "import sys\n",
    "# adding Folder_2 to the system path\n",
    "sys.path.insert(0, '/home/sanj/projects/gaardian/workflow/scripts/')\n",
    "import probetools as probe"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Make a VCF to Zarr function\n",
    "\n",
    "Making use of pandas, and allel.write_vcf_header() function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "def write_vcf_header(vcf_file, contig):\n",
    "    \"\"\"\n",
    "    Writes a VCF header.\n",
    "    \"\"\"\n",
    "    \n",
    "    print('##fileformat=VCFv4.1', file=vcf_file)\n",
    "    # write today's date\n",
    "    today = date.today().strftime('%Y%m%d')\n",
    "    print('##fileDate=%s' % today, file=vcf_file)\n",
    "    # write source\n",
    "    print('##source=scikit-allel-%s + ZarrToVCF.py' % allel.__version__, file=vcf_file)\n",
    "    #write refs and contigs \n",
    "    print('##reference=resources/reference/Anopheles-gambiae-PEST_CHROMOSOMES_AgamP4.fa', file=vcf_file)\n",
    "    print('##contig=<ID=2R,length=61545105>', file=vcf_file) if contig == '2R' else None\n",
    "    print('##contig=<ID=3R,length=53200684>', file=vcf_file) if contig == '3R' else None \n",
    "    print('##contig=<ID=2L,length=49364325>', file=vcf_file) if contig == '2L' else None\n",
    "    print('##contig=<ID=3L,length=41963435>', file=vcf_file) if contig == '3L' else None\n",
    "    print('##contig=<ID=X,length=24393108>', file=vcf_file) if contig == 'X' else None\n",
    "    print('##FORMAT=<ID=GT,Number=1,Type=String,Description=\"Genotype\">', file=vcf_file)\n",
    "\n",
    "\n",
    "def ZarrToPandasToVCF(vcf_file, genotypePath, positionsPath, siteFilterPath, contig, nchunks=50, snpfilter = \"segregating\"):\n",
    "    \n",
    "    \"\"\"\n",
    "    Converts genotype and POS arrays to vcf, using pd dataframes in chunks. \n",
    "    Segregating sites only. Needs REF and ALT arrays.\n",
    "    \"\"\"\n",
    "    \n",
    "    #if file exists ignore and skip\n",
    "    myfile = Path(f\"{vcf_file}.gz\")\n",
    "    if myfile.is_file():\n",
    "        print(f\"File {vcf_file}.gz Exists...\")\n",
    "        return\n",
    "    \n",
    "    probe.log(f\"Loading array for {contig}...\")\n",
    "\n",
    "    geno, pos = probe.loadZarrArrays(genotypePath, positionsPath, siteFilterPath=siteFilterPath, cloud=cloud, contig=contig, sample_sets=ag3_sample_sets, haplotypes=False)\n",
    "    allpos = allel.SortedIndex(zarr.open_array(positionsPath)[:])\n",
    "    ref_alt_filter = allpos.locate_intersection(pos)[0]\n",
    "    \n",
    "    refs = zarr.open_array(refPath.format(contig=contig))[:][ref_alt_filter]\n",
    "    alts = zarr.open_array(altPath.format(contig=contig))[:][ref_alt_filter]\n",
    "    \n",
    "    if snpfilter == \"segregating\":\n",
    "        probe.log(\"Find segregating sites...\")\n",
    "        flt = geno.count_alleles().is_segregating()\n",
    "        geno = geno.compress(flt, axis=0)\n",
    "        positions = pos[flt]\n",
    "        refs = refs[flt].astype(str)\n",
    "        alts = [a +\",\" + b + \",\" + c for a,b,c in alts[flt].astype(str)]\n",
    "    elif snpfilter == 'biallelic':\n",
    "        probe.log(\"Finding biallelic sites and recoding to 0 and 1...\")\n",
    "        ac = geno.count_alleles()\n",
    "        flt = ac.is_biallelic()\n",
    "        geno = geno.compress(flt, axis=0)\n",
    "        ac = ac.compress(flt, axis=0)\n",
    "        ref0 = ac[:,0] > 0                      # Make sure one of bialleles is 0\n",
    "        geno = geno.compress(ref0, axis=0)\n",
    "        ac = ac.compress(ref0, axis=0)\n",
    "\n",
    "        alt_idx = np.where(ac[:,1:] > 0)[1]     # Get alt idx (is it 0,1,2)\n",
    "        mapping = np.tile(np.array([0,1,1,1]), reps=geno.shape[0]).reshape(geno.shape[0], 4) # create mapping to recode bialleles to 1 \n",
    "        geno = geno.map_alleles(mapping)\n",
    "        positions = pos[flt][ref0]\n",
    "        refs = refs[flt].astype(str)[ref0]\n",
    "        alts = np.take_along_axis(alts[flt].astype(str).compute(), alt_idx[:, None], axis=-1) # select correct ALT allele\n",
    "    else:\n",
    "        assert np.isin(snpfilter, ['segregating', \"biallelic01\"]).any(), \"incorrect snpfilter value\"\n",
    "  \n",
    "    probe.log(\"calculating chunks sizes...\")\n",
    "    chunks = np.round(np.arange(0, geno.shape[0], geno.shape[0]/nchunks)).astype(int).tolist()\n",
    "    chunks.append(geno.shape[0])\n",
    "\n",
    "    for idx, chunk in enumerate(chunks[:-1]):\n",
    "\n",
    "        gn = geno[chunks[idx]:chunks[idx+1]].compute()\n",
    "        pos = positions[chunks[idx]:chunks[idx+1]]\n",
    "        ref = refs[chunks[idx]:chunks[idx+1]]\n",
    "        alt = alts[chunks[idx]:chunks[idx+1]]\n",
    "        \n",
    "        # Contruct SNP info DF\n",
    "        vcf_df = pd.DataFrame({'#CHROM': contig,\n",
    "                 'POS': pos,\n",
    "                 'ID': '.',\n",
    "                 'REF': ref,\n",
    "                 'ALT': alt,\n",
    "                 'QUAL': '.',\n",
    "                 'FILTER': '.',\n",
    "                 'INFO':'.',\n",
    "                'FORMAT': 'GT'})\n",
    "\n",
    "        probe.log(f\"Pandas SNP info DataFrame constructed...{idx}\")\n",
    "\n",
    "        # Geno to VCF\n",
    "        vcf = pd.DataFrame(gn.to_gt().astype(str), columns=metadata[sampleNameColumn])\n",
    "        probe.log(\"Concatenating info and genotype dataframes...\")\n",
    "        vcf = pd.concat([vcf_df, vcf], axis=1)\n",
    "\n",
    "        probe.log(f\"Pandas Genotype data constructed...{idx}\")\n",
    "\n",
    "        if (idx==0) is True:\n",
    "            with open(f\"{vcf_file}\", 'w') as vcfheader:\n",
    "                    write_vcf_header(vcfheader, contig)\n",
    "\n",
    "        probe.log(\"Writing to .vcf\")\n",
    "\n",
    "        vcf.to_csv(vcf_file, \n",
    "                   sep=\"\\t\", \n",
    "                   index=False,\n",
    "                   mode='a',\n",
    "                  header=(idx==0), \n",
    "                  line_terminator=\"\\n\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Write multiallelic (segregating snps only) VCF file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "ag3_sample_sets = \"1244-VO-GH-YAWSON-VMF00149\"\n",
    "chroms = ['2L', '2R', '3L', '3R', 'X']\n",
    "contig = '2L'\n",
    "\n",
    "metadata = pd.read_csv(\"../../config/metadata.tsv\", sep=\"\\t\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "geno, pos = probe.loadZarrArrays(\"../../resources/snp_genotypes/all/1244-VO-GH-YAWSON-VMF00149/2L/calldata/GT/\", \n",
    "                                \"../../resources/snp_genotypes/all/sites/2L/variants/POS/\", \n",
    "                                siteFilterPath=\"../../resources/site_filters/dt_20200416/gamb_colu/2L/variants/filter_pass/\", \n",
    "                                cloud=False, contig=contig, sample_sets=ag3_sample_sets, haplotypes=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zarr\n",
    "alts = zarr.open_array(\"../../resources/snp_genotypes/all/sites/2L/variants/ALT/\")[:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading array for 2L...\n",
      "Finding biallelic sites and recoding to 0 and 1...\n"
     ]
    }
   ],
   "source": [
    "sample_set = \"1244-VO-GH-YAWSON-VMF00149\"\n",
    "chroms = ['2L', '2R', '3L', '3R', 'X']\n",
    "cloud=False\n",
    "\n",
    "refPath = f\"../../resources/snp_genotypes/all/sites/{contig}/variants/REF/\"\n",
    "altPath = f\"../../resources/snp_genotypes/all/sites/{contig}/variants/ALT/\"\n",
    "\n",
    "for contig in chroms:\n",
    "    \n",
    "    ZarrToPandasToVCF(f\"../../resources/vcfs/test{contig}.vcf\", \n",
    "                    genotypePath=f\"../../resources/snp_genotypes/all/1244-VO-GH-YAWSON-VMF00149/{contig}/calldata/GT/\", \n",
    "                    positionsPath=f\"../../resources/snp_genotypes/all/sites/{contig}/variants/POS/\", \n",
    "                    siteFilterPath=f\"../../resources/site_filters/dt_20200416/gamb_colu/{contig}/variants/filter_pass/\", \n",
    "                    contig=contig, \n",
    "                    snpfilter=\"biallelic\")\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "interpreter": {
   "hash": "710100144729ec1057471750b60f3250df4296be7eb29e7e87fec32ed718ec4b"
  },
  "kernelspec": {
   "display_name": "Python 3.7.3 64-bit ('pysanj': conda)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
